{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e2dfb4-aef2-4117-8628-399166c4f707",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c53886-28a5-4c09-a3c9-07444e7a5be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa1932f-9ee7-43b3-a9d2-f9f4af4e728a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transformers sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0d6a86-2a03-4fa5-888c-f304a7eea06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5274b13-d442-4862-9748-e462e3562662",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241370c3-2d5b-440c-b45b-43a323c78927",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3777f1-0c25-47e4-bb68-646359ae8aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b7ef1dc4-c7ea-4e48-a554-e75d330eef51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ebakhtina/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import jsonlines\n",
    "import json\n",
    "nltk.download('punkt')\n",
    "from transformers import TrainingArguments\n",
    "import numpy as np\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import Trainer\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from datasets import Dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e4873732-29d4-43a8-a1b8-8c6fac031598",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"tqdm-data.jsonl\"\n",
    "warnings = []\n",
    "with open(path, 'rb') as f:\n",
    "    for item in jsonlines.Reader(f):\n",
    "        message = item.get(\"message\")\n",
    "        if message is not None:\n",
    "            warnings.append(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e22f25d4-b2c2-4f93-9e11-bf556cd57ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "sentences.append('message')\n",
    "for w in warnings:\n",
    "    tmp = sent_tokenize(w)\n",
    "    for elem in tmp:\n",
    "        sentences.append(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d906ea06-1057-42fa-8d30-62dfdb08dae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "class CustomTextDataset(data.Dataset):\n",
    "    def __init__(self, warnings, numbers, transform=None, target_transform=None):\n",
    "        \n",
    "        self.comments = warnings\n",
    "        \n",
    "        self.labels = numbers\n",
    "        \n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.comments)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx < 0 or idx >= len(self.comments):\n",
    "            raise IndexError(\"Index out of range\")\n",
    "        text = self.comments[idx]\n",
    "        label = self.labels[idx]\n",
    "        return text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "09b47093-c017-4e5a-b1f0-d5d0b635864a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "892287c62ea94fff94c6fe4a4126442a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/87 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['message', 'id', 'labels', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 87\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dset = load_dataset(\"json\", data_files=\"tqdm-data.jsonl\", split=\"train\")\n",
    "\n",
    "id = []\n",
    "for i in range(len(dset)):\n",
    "    id.append(i)\n",
    "dset = dset.add_column(\"id\", id)\n",
    "\n",
    "from random import randint\n",
    "numbers = []\n",
    "for i in range(len(dset)):\n",
    "    numbers.append(randint(0, 1))\n",
    "dset = dset.add_column(\"labels\", numbers)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "\treturn tokenizer(examples['message'], padding='max_length', truncation=True)\n",
    "\n",
    "tokenized_dset_of_comments = dset.map(tokenize_function)\n",
    "\n",
    "print(tokenized_dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8b2e4568-cc4f-4f21-8246-e115937e2211",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
    "label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert/distilbert-base-uncased\", num_labels=2, id2label=id2label, label2id=label2id, ignore_mismatched_sizes=True)\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\", learning_rate=6e-6, per_device_train_batch_size=4, num_train_epochs=3)\n",
    "from accelerate import Accelerator\n",
    "accelerator = Accelerator()\n",
    "model, tokenizer = accelerator.prepare(model, tokenizer)\n",
    "# dset = dset.rename_column(\"labels\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1246d231-98fa-46c8-b54d-062620c957f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2d80c5ae-7a34-460d-a674-f0ac4f81fa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred.predictions, eval_pred.label_ids\n",
    "    predictions = np.argmax(logits, axis=1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "67d7cec2-ac3a-458b-83b6-d759627fc383",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer = tokenizer, \n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dset_of_comments,\n",
    "    eval_dataset=tokenized_dset_of_comments,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5a7351c4-3235-42a7-b8ae-84de960434e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 02:52, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:12]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()\n",
    "result = trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e4ff9485-d16e-4051-932e-2e61a5e21e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "numbers_for_sentences = []\n",
    "for i in range(len(sentences)):\n",
    "    numbers_for_sentences.append(randint(0,1))\n",
    "print(numbers_for_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "1659acd1-06c1-4262-b2c6-c246d5065cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_of_sent = []\n",
    "for elem in sentences:\n",
    "    for n in numbers_for_sentences:\n",
    "        d = {elem: n}\n",
    "        prep_of_sent.append(d)\n",
    "        break\n",
    "dataset_of_sentences = Dataset.from_list(prep_of_sent)\n",
    "dataset_of_sentences = dataset_of_sentences.add_column(\"labels\", numbers_for_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d8e162b0-b15b-46f9-9511-19ea799a39e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['message', 'labels'],\n",
       "    num_rows: 170\n",
       "})"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_of_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6e7c05-38d7-4447-bcf4-2409f153335c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
